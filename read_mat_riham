from collections import OrderedDict
import numpy as np
import scipy.io
import matplotlib.pyplot as plt
from bokeh.plotting import figure, show
import os



def plot_lfp(lfp, matplotlib=False, bokeh=False):
    '''
        plot lfp graph
        Args:
            lfp: dictionary with keys and values
            matplotlib (bool): choose lib
            bokeh (bool): choose lib
        Returns:
            dict: dictionary with keys and values
    '''
    const = 300
    colors = ['black', 'navy', 'darkslateblue', 'indigo', 'purple', 'darkorchid', 'firebrick', 'indianred',
              'palevioletred', 'lightcoral', 'salmon', 'sandybrown', 'lightsalmon', 'orange', 'gold', 'yellow', 'yellowgreen']
    data = {}
    for key, value in lfp.items():
        new_key = int(key.split("/")[-1])
        data[new_key] = value

    sorted_keys = sorted(data.keys(), reverse=True)
    ordered_data = OrderedDict()
    for index, key in enumerate(sorted_keys):
        ordered_data[index] = data[key]

    if matplotlib:
        fig, ax = plt.subplots()

        for key, data in ordered_data.items():
            xticks = np.linspace(0, 50, len(data))
            ax.plot(xticks, data + key * const, lw=1.5, color=colors[key])

        ax.set_yticks(np.arange(16) * const)
        ax.set_yticklabels(np.arange(16))

        plt.xlabel('Time (ms)')
        plt.ylabel('Sensors â„– (mV)')
        plt.show()

    if bokeh:
        p = figure(x_axis_label='Time (ms)', y_axis_label='Sensors')
        x_values = np.linspace(0, 50, num=2001)

        for key in ordered_data:
            xticks = x_values
            y_offset = key * 3000
            p.line(xticks, np.array(ordered_data[key]) + y_offset, line_width=2, color=colors[key])
        show(p)

    return ordered_data



def inspect_mat_file(mat_contents, output_dir="files"):
    '''
        Inspect the structure of a .mat file.
        Args:
            mat_contents: Dictionary loaded from a .mat file
            output_dir: Directory to store output text files (default: "files")
        Returns:
            None
    '''
    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    print("Keys in the mat file:", mat_contents.keys())

    for key, value in mat_contents.items():
        print(f"Key: {key}")
        if hasattr(value, 'shape'):
            print(f"Type: {type(value)}, Shape: {value.shape}")
        else:
            print(f"Type: {type(value)}, No shape attribute")
        if isinstance(value, np.ndarray):
            print(f"Array Content Example: {value[:5] if value.size > 5 else value}")  # print a few elements if it's an array

        # Write the value to a file in the output directory
        output_file_path = os.path.join(output_dir, f"{key}.txt")
        with open(output_file_path, 'w') as f:
            f.write(str(value))


def safely_extract_key(mat_contents, key_name):
    '''
        Safely extract a key from a .mat file, with error handling.
        Args:
            mat_contents: Dictionary loaded from a .mat file
            key_name (str): Key to extract from the dictionary
        Returns:
            Extracted data or raises a KeyError
    '''
    if key_name in mat_contents:
        return mat_contents[key_name]
    else:
        raise KeyError(f"Key '{key_name}' not found in the .mat file.")


if __name__ == '__main__':
    # Path to your .mat file
    file_path = 'max.mat'

    # Reading the .mat file
    mat_contents = scipy.io.loadmat(file_path)

    # Inspect the contents and structure of the .mat file
    inspect_mat_file(mat_contents, output_dir="output_files")  # Specify the output directory


    # Extracting data safely with error handling
    try:
        lfp_data = safely_extract_key(mat_contents, 'lfpAnalys')
        spks_data = safely_extract_key(mat_contents, 'parAnalys')
    except KeyError as e:
        print(e)
        exit(1)  # Exit if keys not found

    # Visualizing neuronal activity for all neurons
    fig, axs = plt.subplots(lfp_data.shape[0], 1, figsize=(12, 2 * lfp_data.shape[0]), sharex=True)

    for neuron_index in range(lfp_data.shape[0]):
        neuron_lfp = lfp_data[neuron_index]
        neuron_spk = spks_data[neuron_index][0][0]  # Extracting spike time stamps

        # Creating a time scale for LFP data
        time_lfp = np.linspace(0, len(neuron_lfp), num=len(neuron_lfp))

        axs[neuron_index].plot(time_lfp, neuron_lfp, label=f'Neuron {neuron_index + 1} LFP')

        # Adding spikes
        spike_times = [int(time) for sublist in neuron_spk for time in sublist if int(time) < len(neuron_lfp)]
        spike_values = [neuron_lfp[int(time)] for time in spike_times if int(time) < len(neuron_lfp)]

        # Ensuring array sizes match
        if len(spike_times) == len(spike_values):
            axs[neuron_index].scatter(spike_times, spike_values, color='red',
                                      label=f'Neuron {neuron_index + 1} Spikes')

        axs[neuron_index].set_ylabel('LFP Amplitude')
        axs[neuron_index].legend(loc='upper right')

    # Setting axes and title
    plt.xlabel('Time')
    fig.suptitle('Neuronal Activity (LFP) with Spike Times for All Neurons')
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()
